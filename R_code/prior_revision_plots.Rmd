---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 




```{r}
prefix = "/Users/noa/Workspace/raxml_deep_learning_results/group_revision_files/"
full_data = read_tsv(paste(prefix,"group_results.tsv", sep = ""))
test_data = read_tsv(paste(prefix,"final_performance_on_test_M_frac_1.0_eps_0.1_RFE_True_large_grid_True_out_features_True.tsv",sep = ""))
#val_data = read_tsv(paste(prefix,"final_performance_on_val_M_frac_1.0_RFE_True_large_grid_False_out_features_True.tsv",sep = ""))
error_vs_size = read_tsv(paste(prefix,"group_classification_metrics_eps_0.1.tsv",sep = ""))
error_vs_group = read_tsv(paste(prefix,"group_classification_group_metrics_M_frac_1.0_eps_0.1_RFE_True_large_grid_True_out_features_True_eps_0.1.tsv",sep = ""))
```
```{r}
full_data_0.001<- full_data %>% filter (ll_epsilon==0.001)
```

Required number of starting trees

```{r}
full_data_0.1<- full_data %>% filter (ll_epsilon==0.1)
full_data_0.1$binned_n_trees<- cut(full_data_0.1$n_total_trees_sampled, breaks=c(0,5,10,15,20,25,30,35,40))
full_data_0.1$binned_pythia<- cut(full_data_0.1$feature_msa_pypythia_msa_difficulty, breaks=c(0,0.2,0.4,0.6,1))
full_data_0.1 %>% group_by(n_total_trees_sampled,binned_pythia ) %>% summarise(mean_ll_diff = mean(default_final_err), mean_pct_global = mean (default_status)) %>% ggplot(aes(x=n_total_trees_sampled, y = mean_pct_global, color = binned_pythia,group =binned_pythia))+geom_point()+geom_line() + expand_limits(y = 0) + theme(text = element_text(size = 13)) +labs(title = "", x = "Number of starting trees", y = "% Global maximum", color = "MSA difficulty")
full_data %>% distinct (msa_path)



```

SPR radius and SPR cutoffs
```{r}

full_data_0.1 %>% filter (spr_cutoff>0) %>% group_by(spr_cutoff, binned_pythia) %>% summarise(mean_ll_diff = mean(default_final_err), mean_pct_global = mean (default_status)) %>% ggplot(aes(x=spr_cutoff, y = mean_pct_global,color = binned_pythia, groups = binned_pythia))+geom_point()+geom_line()+ expand_limits(y = 0)


full_data_0.1 %>% group_by(spr_radius,binned_pythia) %>% filter (spr_radius>0) %>% summarise(mean_ll_diff = mean(default_final_err), mean_pct_global = mean (default_status)) %>% ggplot(aes(x=spr_radius, y = mean_pct_global, color = binned_pythia, groups = binned_pythia))+geom_point()+geom_line()+ expand_limits(y = 0)
```






Data Per Source
```{r}
full_data_0.1 %>%  filter (grepl('Pandit',msa_path)) %>% distinct (msa_path) 
full_data_0.1 %>%  filter (grepl('Selectome',msa_path)) %>% distinct (msa_path) 
full_data_0.1 %>%  filter (grepl('DNA',msa_path)) %>% distinct (msa_path)
full_data_0.1 %>%  filter (grepl('PROTEIN',msa_path)) %>% distinct (msa_path)
```

Statistics on mean global max probability

```{r}

summary(full_data_0.1 %>% pull (feature_msa_n_loci))

summary(full_data_0.1 %>% pull (default_status))

data<-full_data_0.1 %>% filter (n_total_trees_sampled>20) %>% group_by(msa_path) %>% summarise(mean_prob = mean(default_status))

summary(data %>% pull (mean_prob))

data
(data %>% filter (mean_prob>0.9))
(data %>% filter (mean_prob>0.5))
(data %>% filter (mean_prob<0.1))
(data %>% filter (mean_prob<0.05))


```


Confusion matrix
```{r}

ggplotConfusionMatrix <- function(m){
  mytitle <- ""#paste("Accuracy", percent_format()(m$overall[1]))
                  # "Kappa", percent_format()(m$overall[2]))
  p <-
    ggplot(data = as.data.frame(m$table) ,
           aes(x = Reference, y = Prediction)) +
    geom_tile(aes(fill = log(Freq)), colour = "white") +
    scale_fill_gradient(low = "white", high = "steelblue") +
    geom_text(aes(x = Reference, y = Prediction, label = Freq)) +
    theme(legend.position = "none") +
    ggtitle(mytitle)+theme(text = element_text(size = 13))
  return(p)
}
conf_data<-test_data %>% dplyr::select (uncalibrated_prob, default_status) %>% mutate (pred_status = round(uncalibrated_prob)) 

obs<- factor(conf_data %>% pull (default_status))
pred<- factor(conf_data %>% pull (pred_status))


confusion_plot<-ggplotConfusionMatrix(confusionMatrix(data = pred, reference= obs))+theme(legend.position = "none")
confusion_plot
```

Error vs size
```{r}
library(predtools)
library(MASS)
library(caret)


error_vs_size_plt = error_vs_size %>% mutate(n_MSAs = round(868*sample_fraction)) %>% ggplot(aes(x=n_MSAs, y = AUC))+geom_line()+ expand_limits(y = 0.5)+xlab("Number of MSAs")+ theme(text = element_text(size = 13))+ylab("AUC")+geom_point()

rocobj <- roc(test_data$default_status, test_data$calibrated_prob)
auc <- round(auc(test_data$default_status, test_data$calibrated_prob),3)

global_max_auc_plt<-ggroc(rocobj,colour = 'steelblue', size = 2)+
  ggtitle(paste0('AUC = ', auc))+theme(text = element_text(size = 13))+xlab("Specificity")


calibration_plt<-xyplot(calPlotData, auto.key = list(columns = 2),xlab="Observed",ylab="Predicted")



ggarrange(global_max_auc_plt,confusion_plot,error_vs_size_plt, calibration_plt ,labels = c("A","B","C","D"),align = "h", nrow = 2, ncol = 2 ,vjust= 1)


test_data%>% group_by (default_status) %>% count()

```




```{r}
error_vs_group %>% filter (grouping_col_name =='n_seq_group')  %>% distinct (grouping_col)
```



```{r}
library(lme4)


data_for_glm<-full_data %>% dplyr::select (msa_path, feature_msa_n_seq, spr_radius,spr_cutoff,n_rand_trees_sampled,n_pars_trees_sampled, default_status, feature_msa_pypythia_msa_difficulty) %>% mutate(default_status = as.factor(default_status)) %>% mutate(across(where(is.numeric), scale))

model<-glmer(formula = default_status ~ 1 + feature_msa_n_seq+(spr_radius+spr_cutoff+n_rand_trees_sampled+n_pars_trees_sampled)*feature_msa_n_seq+ (1|msa_path),
                           data    = data_for_glm,family = binomial) #to run the model
print(summary(model))
```




```{r}
library(dplyr)
library(MASS)

Pypythia_error<-error_vs_group %>% filter (grouping_col_name =='msa_difficulty_group') %>% ggplot(aes(y=grouping_col, x=AUC))+geom_col()+ expand_limits(y = c(0.5,1))+ylab('MSA\ndifficulty')+ xlab('AUC')+theme(text = element_text(size = 10))


n_seq_error<-error_vs_group %>% filter (grouping_col_name =='n_seq_group') %>% mutate(grouping_col = factor(grouping_col, levels = c('(29.999, 45.0]','(45.0, 67.0]','(67.0, 108.0]','(108.0, 199.0]'))) %>% ggplot(aes(y=grouping_col, x=AUC))+geom_col()+ expand_limits(y = c(0.5,1))+ylab('Number\nof sequences')+xlab('AUC')+theme(text = element_text(size = 10))

n_loci_error<-error_vs_group %>% filter (grouping_col_name =='feature_msa_n_loci')  %>%  mutate(grouping_col = factor(grouping_col, levels = c('(99.999, 239.0]','(239.0, 632.0]','(632.0, 1437.0]','(1437.0, 12478.0]'))) %>% ggplot(aes(y=grouping_col, x=AUC))+geom_col()+ expand_limits(y = c(0.5,1))+ylab('Number\nof positions')+xlab('AUC')+theme(text = element_text(size = 10))


Pypythia_scatter<-test_data %>% dplyr::select (msa_path,uncalibrated_prob,calibrated_prob,  feature_msa_pypythia_msa_difficulty) %>% group_by(msa_path,feature_msa_pypythia_msa_difficulty) %>% summarise(mean_prob = mean(calibrated_prob)) %>% ggplot(aes(x=feature_msa_pypythia_msa_difficulty, y = mean_prob))+geom_point(size = 0.7)+xlab("MSA\ndifficulty")+ylab("Predicted\nprobability")+theme(text = element_text(size = 10))

seq_scatter<-test_data %>% dplyr::select (msa_path,uncalibrated_prob,calibrated_prob, feature_msa_n_seq, feature_msa_pypythia_msa_difficulty) %>% group_by(msa_path,feature_msa_n_seq) %>% summarise(mean_prob = mean(calibrated_prob)) %>% ggplot(aes(x=feature_msa_n_seq, y = mean_prob))+geom_point(size = 0.7)+xlab("Number of\nsequences")+ylab("Predicted\nprobability")+theme(text = element_text(size = 10))

n_loci_scatter<-test_data %>% dplyr::select (msa_path,uncalibrated_prob,calibrated_prob, feature_msa_n_loci) %>% group_by(msa_path,feature_msa_n_loci) %>% summarise(mean_prob = mean(calibrated_prob)) %>% ggplot(aes(x=feature_msa_n_loci, y = mean_prob))+geom_point(size = 0.7)+xlab("Number of\n positions")+ylab("Predicted\nprobability")+theme(text = element_text(size = 10))


ggarrange(seq_scatter,Pypythia_scatter,n_loci_scatter, n_seq_error,Pypythia_error, n_loci_error,labels = c("A","C","E","B","D","F"),align = "h", nrow = 3, ncol = 3, legend = "bottom",vjust= 1)
#error_vs_group_5_5_including_plt


cor.test(test_data$feature_msa_pypythia_msa_difficulty, test_data$uncalibrated_prob)
cor.test(test_data$feature_msa_n_seq, test_data$uncalibrated_prob)
cor.test(test_data$feature_msa_n_loci, test_data$uncalibrated_prob)
```






Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

