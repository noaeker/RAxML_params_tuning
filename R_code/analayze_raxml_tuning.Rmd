---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
library(lme4)
library(ggplot2)
library(plotrix)
library(visreg)
library(stringr)
library(tidyverse)
library(ggpubr)
library(gridExtra)
library(tidyverse)
library(tidymodels)
library(vip) 
library(plm)
library(survival)
library(survminer)
library(cmprsk)
library(tidyverse)
library(caret)
library(survival)
library(survminer)
library(lubridate)



```




```{r}
tuning_data<- read_tsv("/Users/noa/Workspace/raxml_deep_learning_results/single_gene_MSAs/full_raxml_data.tsv")
default_running_time_and_ll<- tuning_data %>% filter (run_name=="default") %>% select (msa_name, starting_tree_ind, elapsed_running_time,delta_ll_from_curr_starting_tree_best_topology) %>% rename (default_elapsed_time = elapsed_running_time, default_delta_ll_from_curr_starting_tree = delta_ll_from_curr_starting_tree_best_topology )

tuning_data<-tuning_data %>% inner_join(default_running_time_and_ll, by = c("msa_name", "starting_tree_ind")) %>% mutate(status = ifelse(delta_ll_from_overall_msa_best_topology == 0,2,1), curr_tree_status = ifelse(delta_ll_from_curr_starting_tree_best_topology == 0,1,2)) %>%  mutate (istate = "entry",relative_to_default_time_to_event = elapsed_running_time/default_elapsed_time, tree_type_labeled = tree_type=="parsimony")# %>% sample_n(10000)
tuning_data$endpoint = factor(tuning_data$status,levels = c(0,1,2), labels = c(0,1,2)) 


tuning_data<- tuning_data %>% mutate (n_seq_binned =ntile(tuning_data$n_seq,3),n_loci_binned =ntile(tuning_data$n_loci,4)) %>% group_by(starting_tree_ind, msa_name) %>%  mutate(normalized_delta_ll_from_tree = delta_ll_from_curr_starting_tree_best_topology/-max(final_ll)) %>% ungroup()
                                                                                                

```




```{r}
res.cox <- coxph(Surv(relative_to_default_time_to_event, curr_tree_status) ~ as.factor(tree_type), data = tuning_data)
summary(res.cox)

```

```{r}

fit <- survfit(res.cox, data = tuning_data)
ggsurvplot(fit,legend.labs=c("tree_type"), conf.int = TRUE,risk.table = TRUE,
           ggtheme = theme_minimal())
```



```{r}
tuning_data  %>% filter(run_name!="default") %>% group_by(spr_radius,spr_cutoff, tree_type,n_seq_binned) %>% summarise(median_delta_ll = median(normalized_delta_ll_from_tree)) %>% ggplot(aes(y=median_delta_ll,x= spr_radius, color =tree_type ))+geom_line()+ facet_grid(cols =vars(n_seq_binned), rows = vars(spr_cutoff)) #vars(n_loci_binned), 
```


```{r}
msa_characteristics<-tuning_data %>%  distinct (msa_name, n_seq, n_loci)

tuning_data %>% ggplot(aes(x=n_seq, fill = as.factor(n_seq_binned))) +geom_histogram()
tuning_data %>% ggplot(aes(x=n_loci, fill = as.factor(n_loci_binned))) +geom_histogram()


tuning_data %>% distinct(msa_type)
tuning_data %>% distinct (spr_radius)
tuning_data %>% distinct (spr_cutoff)
```
Defaults

```{r}
tuning_data %>% filter(run_name=="default") %>% distinct (spr_radius)
tuning_data %>% filter(run_name=="default") %>% distinct (spr_cutoff)
```

```{r}
#default_elapsed_time,default_delta_ll_from_curr_starting_tree
best_per_starting_tree<-tuning_data %>% filter(delta_ll_from_curr_starting_tree_best_topology==0)  %>%  group_by(starting_tree_ind, msa_name)   %>%  filter(elapsed_running_time == min(elapsed_running_time)) %>% mutate(default_time_pct = (default_elapsed_time-elapsed_running_time)/ elapsed_running_time, default_status =  ifelse(run_name=="default", "default_is_best", ifelse(default_delta_ll_from_curr_starting_tree>0 & default_time_pct>0   ,"less_accurate_and_slower",ifelse(default_delta_ll_from_curr_starting_tree>0 & default_time_pct<0   ,"less_accurate_and_faster",ifelse(default_delta_ll_from_curr_starting_tree==0 & default_time_pct>0,"accurate_but_slower","NA")))))

best_per_starting_tree %>% ggplot (aes(default_time_pct, fill = msa_type)) + geom_histogram()
best_per_starting_tree %>% ggplot (aes(default_delta_ll_from_curr_starting_tree, fill = msa_type )) + geom_histogram()
summary(best_per_starting_tree %>% pull(default_delta_ll_from_curr_starting_tree))
best_per_starting_tree %>% ggplot (aes(default_status, fill = default_status )) + geom_histogram(stat="count") + theme(axis.text.x = element_text(angle = 60, vjust = 1, hjust=1))  

```




```{r}

tuning_data %>% filter(run_name!="default",spr_cutoff == 2.575,msa_name=="_ChenA4_Pro_ENSG00000116221.refined.fas") %>% ggplot(aes(y=delta_ll_from_curr_starting_tree_best_topology, x = spr_radius, group = interaction(starting_tree_ind, tree_type, msa_name), colour = tree_type)) + geom_line()

tuning_data %>% filter(run_name!="default",spr_cutoff == 2.575,msa_name=="_StruA5_gene731_22612.aln") %>% ggplot(aes(y=delta_ll_from_curr_starting_tree_best_topology, x = spr_radius, group = interaction(starting_tree_ind, tree_type, msa_name), colour = tree_type)) + geom_line()


tuning_data %>% filter(run_name!="default",spr_cutoff == 2.575,msa_name=="_WickD3a_7865.aln") %>% ggplot(aes(y=delta_ll_from_curr_starting_tree_best_topology, x = spr_radius, group = interaction(starting_tree_ind, tree_type, msa_name), colour = tree_type)) + geom_line(position = position_dodge(width = 0.1))

tuning_data %>% filter(run_name!="default",spr_cutoff == 2.575,msa_name=="_MisoD2a_EOG576HF8.aln") %>% ggplot(aes(y=delta_ll_from_curr_starting_tree_best_topology, x = spr_radius, group = interaction(starting_tree_ind, tree_type, msa_name), colour = tree_type)) + geom_line(position = position_dodge(width = 0.1))


```

Learning

```{r}

set.seed(123)
training.samples <-tuning_data$curr_tree_status %>% 
  createDataPartition(p = 0.8, list = FALSE)
train.data  <- tuning_data[training.samples, ]
test.data <- tuning_data[-training.samples, ]

```


```{r}
tuning_data$curr_tree_status = as.factor(tuning_data$curr_tree_status)
model <- glm( (curr_tree_status) ~as.factor(spr_radius)+tree_type+spr_cutoff+n_seq+n_loci, data = tuning_data, family = binomial)
summary(model)
```


```{r}
probabilities <- model %>% predict(train.data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
mean(predicted.classes == train.data$curr_tree_status)


probabilities <- model %>% predict(test.data, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
mean(predicted.classes == test.data$curr_tree_status)
```

```{r}
train.data %>%
  mutate(prob = ifelse(diabetes == "pos", 1, 0)) %>%
  ggplot(aes(glucose, prob)) +
  geom_point(alpha = 0.2) +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  labs(
    title = "Logistic Regression Model", 
    x = "Plasma Glucose Concentration",
    y = "Probability of being diabete-pos"
    )
```


```{r}
library(jtools)
linear.mod
linear.mod<- lm(delta_ll_from_curr_starting_tree_best_topology/ n_loci~as.factor(spr_radius)+tree_type+spr_cutoff+n_seq+n_loci, data =tuning_data )
summary(linear.mod)
summ(linear.mod)
#interact_plot(linear.mod, pred = spr_radius, modx = tree_type)
#interaction.plot(x.factor =tuning_data)
```





```{r}

default_tuning_data = tuning_data %>% filter (run_name=="default")

fit<-cuminc(
    ftime = default_tuning_data$relative_time_to_event, 
    fstatus = default_tuning_data$endpoint, 
    cencode = 0
    )

ggcompetingrisks(
    fit,
    xlab = "Time"
    )


```



```{r}
fit<-crr(
    ftime = tuning_data$relative_time_to_event, 
    fstatus = tuning_data$endpoint, 
    cencode = 0,failcode=2,
    cov1 = tuning_data[,c("spr_cutoff","spr_radius","n_seq","n_loci","tree_type")]
    )
fit

summary(fit)

```




```{r}

x<-predict.crr(fit,cov1 = rbind(0.1,500,100,100,1))
plot(x)
```




Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

